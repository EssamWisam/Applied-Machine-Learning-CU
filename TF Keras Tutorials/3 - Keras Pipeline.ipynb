{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔮 Deep Learning in Practice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen, Keras forms the core of the TensorFlow deep learning pipeline and we will see later that it can be viewed as a standalone package that doesn't necessarily depend on TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/SbcHrMK.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📊 Keras.utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Keras.utils` has data loading capabilities (including different formats: image, audio, text, time series) as well as other utilities (e.g., plotting model architecture). Recall, `torch.utils.data` is also what handled data loading in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 244 files belonging to 2 classes.\n",
      "Found 153 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "\n",
    "train_data = image_dataset_from_directory(\n",
    "    directory='./data/Hymenoptera/train',\n",
    "    labels='inferred',                              # i.e., infer classes from folders (otherwise, directory structure ignored)\n",
    "    label_mode='int',                               # automatically assign labels as integers (can also choose one-hot)\n",
    "    batch_size=32,                                  # batch size\n",
    "    image_size=(224, 224),                          # Size to resize images to after they are read from disk\n",
    "    seed=42  \n",
    ")\n",
    "\n",
    "val_data = image_dataset_from_directory(\n",
    "    directory='./data/Hymenoptera/val',\n",
    "    batch_size=32,  \n",
    "    image_size=(224, 224), \n",
    "    seed=42 \n",
    ")\n",
    "\n",
    "# this is equivalent to doing lots of tensorflow work:\n",
    "assert isinstance(train_data, tf.data.Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarily, there is `text_dataset_from_directory` function and `audio_dataset_from_directory` where `labels='inferred'` has the same behaviour. Check them out [here](https://keras.io/api/data_loading/). \n",
    "\n",
    "PyTorch also has the capability of easily reading different formats but they as delegated to friendly packages such as`torchvision`, `torchaudio` and `torchtext`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🗂️ Keras.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, `Keras.datasets` has some built-in datasets for image, text and regression. In PyTorch, image datasets were in `torchvision` and text datasets were in `torchtext` (as well as audio datasets in `torchaudio`). \n",
    "\n",
    "For a list of datasets, [see](https://keras.io/api/datasets/).\n",
    "\n",
    "Note that it reads them as Numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "assert x_train.shape == (60000, 28, 28)\n",
    "assert type(x_train) == np.ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module is limited in terms of the number of datasets available and that it returns them in Numpy arrays (still need to wrap in TensorFlow dataset). Much more datasets can be loaded in `Dataset` format from [TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/overview#all_datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-18 13:49:46.989541: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow-datasets\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Construct a tf.data.Dataset\n",
    "train_dataset = tfds.load('mnist', split='train', as_supervised=True, shuffle_files=True)\n",
    "\n",
    "# Build your input pipeline\n",
    "train_dataset = train_dataset.shuffle(1000).batch(128).take(5)\n",
    "for xb, yb in train_dataset:\n",
    "  assert xb.shape == (128, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🏷️ Keras.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like what you would expect, this implements a large variety of deep learning layers (e.g., linear, convolutional, recurrent, attention, etc.) and activation functions.\n",
    "\n",
    "They behave much like in PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 32])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "layer = layers.Dense(32, activation='relu')         # a layer with 32 neurons; input size will be inferred on first call\n",
    "inputs = tf.random.uniform(shape=(16, 20))          # batch of 16 examples, each of dimensionality 20\n",
    "outputs = layer(inputs)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining custom layers similar to PyTorch is also possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 32])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Linear(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_dim=20, output_dim=32):\n",
    "        super().__init__()\n",
    "        self.w = self.add_weight(shape=(input_dim, output_dim),trainable=True)\n",
    "        self.b = self.add_weight(shape=(output_dim,), initializer=\"zeros\", trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    \n",
    "\n",
    "layer = Linear(20, 32)                               # a layer with 32 neurons; input size will be inferred\n",
    "inputs = tf.random.uniform(shape=(16, 20))          # batch of 16 examples, each of dimensionality 20\n",
    "outputs = layer(inputs)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's straightforward make your layer infer the `input_dim` via the `build` function and it's considered good practice. Check [here](https://keras.io/guides/making_new_layers_and_models_via_subclassing/) to learn how. \n",
    "\n",
    "For now, let's make another block using the layer we just created and use activation functions along the way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the block has a total of 2373 parameters distribued over 6 weights\n"
     ]
    }
   ],
   "source": [
    "class MLPBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_1 = Linear(20, 32)\n",
    "        self.linear_2 = Linear(32, 50)\n",
    "        self.linear_3 = Linear(50, 1)\n",
    "        self.relu = tf.keras.layers.ReLU()          # can be treated as a layer like PyTorch (at least in this case)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.linear_1(inputs)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = tf.keras.activations.relu(x)            # a THIRD alternative (similar to torch.nn.functional) => use this or specify in dense\n",
    "        return self.linear_3(x)\n",
    "    \n",
    "\n",
    "mlp = MLPBlock()\n",
    "y = mlp(tf.random.uniform(shape=(16, 20)) )  \n",
    "# Notice that we get automatic parameter tracking similar to torch.nn.Module:\n",
    "print(f\"the block has a total of {mlp.count_params()} parameters distribued over {len(mlp.weights)} weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📉 Keras.losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, an API too similar to that of PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03897997"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [0, 1, 0, 0]\n",
    "y_pred = [0.01, 0.9, 0.01, 0.03]\n",
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "bce(y_true, y_pred).numpy()                 # NOTE: PyTorch did bce(y_pred, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002775001"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = tf.keras.losses.mean_squared_error(y_true, y_pred).numpy()        # snake_case for functional loss\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🚀 Keras.optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to PyTorch except that the parameters and their gradients must be passed with each optimization step and `apply_gradients` instead of `step`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after one step: 0.77470434\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "mlp = MLPBlock()\n",
    "\n",
    "# Define optimizer and loss\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "criterion = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "# Generate random input data\n",
    "x = tf.random.uniform(shape=(16, 20))\n",
    "y_true = tf.random.uniform(shape=(16, 1))\n",
    "\n",
    "# Take one step of optimization\n",
    "with tf.GradientTape() as tape:\n",
    "    y_pred = mlp(x)\n",
    "    loss = criterion(y_true, y_pred)\n",
    "\n",
    "gradients = tape.gradient(loss, mlp.trainable_variables)                #  mlp.trainable_variables like mlp.params in PyTorch\n",
    "optimizer.apply_gradients(zip(gradients, mlp.trainable_variables))      # it takes a list of gradient, variable pairs (hence we used zip)\n",
    "\n",
    "print(\"Loss after one step:\", loss.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can also pass a scheduler while instantiating the optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    }
   ],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📈 Keras.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch does not natively support metrics. There is an independent package [torch metrics](https://github.com/Lightning-AI/torchmetrics) for that but native support as in Keras is even better. They are treated similar to loss functions but also have the ability to be updated over multiple steps (e.g., batches):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Define metric\n",
    "accuracy = tf.keras.metrics.Accuracy()\n",
    "\n",
    "# Generate some example data\n",
    "y_true = tf.constant([1, 0, 1, 1])  \n",
    "y_pred = tf.constant([0, 0, 1, 1])  \n",
    "\n",
    "# Update state with the first half of the data\n",
    "accuracy.update_state(y_true[:2], y_pred[:2])\n",
    "print(\"Accuracy:\", accuracy.result().numpy())\n",
    "\n",
    "# Calculate Accuracy after also including the second half\n",
    "accuracy.update_state(y_true[2:], y_pred[2:])\n",
    "print(\"Accuracy:\", accuracy.result().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be [seen](https://keras.io/api/metrics/), they cover most metrics you will ever need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/7cwS47a.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we only need to look at `keras.callbacks`, `keras.ops`. But before we do we will talk about two more keras packages: `KerasCV`, `KerasNLP`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 👁️ KerasCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Similar to `torchvision`, this provides transformations for images (but in the form of layers this time)\n",
    "- Like `torchvision` it also provides pretrained vision models (another submodule `keras.applications` also comes with pretrained vision models)\n",
    "- Unlike `torchvision`, no datasets or data reading functions (we discussed both of these above) but provides more loss functions for vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use to load a StableDiffusion model (out of scope) that can convert text to images by repeately applying diffusion on noise:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the transformations can be done in a more low-level fasion via `tensorflow.image`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([8, 7, 7, 960])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras_cv\n",
    "\n",
    "# Load architecture and weights from preset\n",
    "backbone = keras_cv.models.MobileNetV3Backbone.from_preset(\"mobilenet_v3_large_imagenet\", load_weights=False)\n",
    "\n",
    "input_data_shape = (8, 224, 224, 3)          # batch of 8 images each of dimensions (224, 224, 3) => notice difference to PyTorch (channels)\n",
    "input_data = tf.random.uniform(shape=input_data_shape, minval=0, maxval=1)\n",
    "output = backbone(input_data)\n",
    "output.shape                                 # the backbone does not include the output classification layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see an example augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_hue = keras_cv.layers.RandomHue(factor=0.3, value_range=[0,1])\n",
    "augmented_images = random_hue(input_data)\n",
    "assert not tf.reduce_all(tf.equal(augmented_images, input_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that other augmentations also exist as layers in `keras.layers`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📝 KerasNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel to `KerasCV`, we also have `KerasNLP` for text. It provides:\n",
    "- Pretrained text models\n",
    "- Preprocessing layers (e.g., to add start/end token, random deletion of tokens, etc.)\n",
    "\n",
    "As well as, tokenizers, transformer layers and NLP metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_nlp\n",
    "\n",
    "vocab = [\"[UNK]\", \"the\", \"qu\", \"##ick\", \"br\", \"##own\", \"fox\", \".\"]\n",
    "inputs = [\"The quick brown fox.\"]\n",
    "tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
    "     vocabulary=vocab,\n",
    "     sequence_length=10,\n",
    "     lowercase=True,\n",
    " )\n",
    "outputs = tokenizer(inputs)\n",
    "np.array(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They have many common NLP models (backbone, full classlifier, preprocessor layers, tokenizers) as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 12, 768])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = {\n",
    "    \"token_ids\": np.ones(shape=(1, 12), dtype=\"int32\"),                     # example sequence\n",
    "    \"segment_ids\": np.array([[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0]]),        # to distinguish two sequences\n",
    "    \"padding_mask\": np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]]),       # to ignore padding tokens\n",
    "}\n",
    "\n",
    "# Pretrained BERT encoder.\n",
    "model = keras_nlp.models.BertBackbone.from_preset(\"bert_base_en_uncased\", load_weights=False)\n",
    "model(input_data)['sequence_output'].shape          # maps the 12 tokens into contextual embeddings of 768D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, [HuggingFace](https://huggingface.co/models) is more common for such types of workflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
