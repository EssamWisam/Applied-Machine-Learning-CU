{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”® Deep Learning in Practice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Have Considered PyTorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only as a tensor library (i.e., like Numpy) but which also offers GPU support and automatic differentiation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/FXSdMjM.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr> <th>torch</th> <th>torch.nn</th> <th>torch.nn.functional</th> <th>torch.optim</th> <th>torch.utils</th> </tr>\n",
    "  <tr> \n",
    "  <td> Wraps all other modules and offers tensor functionality on GPU and automatic differentiation </td> \n",
    "  <td> Basic blocks of neural networks (i.e., layers, activations and loss functions) </td> \n",
    "  <td> Stateless functional version of (torch.nn) </td> \n",
    "  <td> Optimization algorithms and learning rate schedulers</td> \n",
    "  <td> reading data, batching, logging, etc. </td> </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside from these modules, PyTorch also made other libraries such as `torchvision`, `torchtext` and `torchaudio`. These in general provide **transformations** specific to the data type (e.g., rotation for images, pitch shift for audio, tokenization for text) as well as built-in known datasets and models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's obvious we're done with the main module `torch` since last tutorial, let's explore the rest:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“Š Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look into `torch.utils.data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With PyTorch, you must start wrap your data in a `Dataset` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first example of dataset: (tensor([0.3000, 2.1000, 3.3000, 4.2000, 3.5000]), tensor(0))  where dataset is of length: 5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
    "\n",
    "x_data = torch.tensor([\n",
    "    [0.3, 2.1, 3.3, 4.2, 3.5],\n",
    "    [1.4, 2.5, 3.6, 4.1, 5.5], \n",
    "    [1.2, 2.1, 3.4, 0.4, 5.9], \n",
    "    [0.2, 2.1, 7.4, 0.4, 5.9], \n",
    "    [1.3, 6.1, 3.4, 1.4, 2.9], \n",
    "\n",
    "    ])\n",
    "y_data = torch.tensor([0, 1, 0, 1, 0])\n",
    "# obvious fact: x and y can come from numpy arrays\n",
    "\n",
    "dataset = TensorDataset(x_data, y_data)\n",
    "print(\"first example of dataset:\", dataset[0], \" where dataset is of length:\", len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And split it into different sets if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now the train dataset is of length: 4 and the validation dataset is of length: 1\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset randomly into training and validation sets\n",
    "train_dataset, val_dataset = random_split(dataset, [0.8, 0.2])\n",
    "print(f\"now the train dataset is of length: {len(train_dataset)} and the validation dataset is of length: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our `Dataset` object, you can use `DataLoader` which for FREE gives you:\n",
    "\n",
    "- Automatic batching and random sampling \n",
    "\n",
    "- Multiprocessing data loading and memory pinning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True,\n",
    "                          sampler=None,                     # SequentialSampler by default\n",
    "                          num_workers=0\n",
    "                          )\n",
    "\n",
    "val_loader = DataLoader(val_dataset, \n",
    "                        batch_size=batch_size, \n",
    "                        shuffle=False,\n",
    "                        sampler=None,\n",
    "                        num_workers=0\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object it returns is a non-indexable iterable (i.e., can loop on it but not index it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Number: 0\n",
      "Inputs: tensor([[1.3000, 6.1000, 3.4000, 1.4000, 2.9000],\n",
      "        [1.2000, 2.1000, 3.4000, 0.4000, 5.9000]])\n",
      "Targets: tensor([0, 0])\n",
      "Batch Number: 1\n",
      "Inputs: tensor([[0.3000, 2.1000, 3.3000, 4.2000, 3.5000],\n",
      "        [1.4000, 2.5000, 3.6000, 4.1000, 5.5000]])\n",
      "Targets: tensor([0, 1])\n"
     ]
    }
   ],
   "source": [
    "for i, (inputs, targets) in enumerate(train_loader):\n",
    "    print(\"Batch Number:\", i)\n",
    "    print(\"Inputs:\", inputs)\n",
    "    print(\"Targets:\", targets)\n",
    "    if i == 1: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, most datasets you will come across will be unstructured and locally stored (i.e., `TensorDataset` not so helpful). \n",
    "\n",
    "**Generic Solution:** \n",
    "\n",
    "Just make a class that loads your dataset and inherit the `Dataset` class from `PyTorch`. \n",
    "\n",
    "```Python\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, params):\n",
    "        pass\n",
    "\n",
    "    def __len__(self):                      # Condition 1: must have length\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, idx):             # Condition 2: and be indexable\n",
    "        pass\n",
    "```\n",
    "\n",
    "Now instead of `dataset = TensorDataset(x_data, y_data)` we will do `dataset = CustomDataset(params)` and implement the methods and the rest will just work!\n",
    "\n",
    "Let's see a basic example. Want to load Sklearn datasets into PyTorch while side stepping any type or format conversions (as these aren't always possible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.2000, 3.2000, 6.0000, 1.8000],\n",
      "        [6.3000, 3.3000, 4.7000, 1.6000],\n",
      "        [6.6000, 3.0000, 4.4000, 1.4000],\n",
      "        [4.5000, 2.3000, 1.3000, 0.3000],\n",
      "        [4.6000, 3.6000, 1.0000, 0.2000],\n",
      "        [4.8000, 3.4000, 1.9000, 0.2000],\n",
      "        [5.2000, 2.7000, 3.9000, 1.4000],\n",
      "        [5.5000, 2.5000, 4.0000, 1.3000],\n",
      "        [5.6000, 3.0000, 4.5000, 1.5000],\n",
      "        [6.4000, 3.2000, 4.5000, 1.5000],\n",
      "        [5.0000, 3.4000, 1.6000, 0.4000],\n",
      "        [5.0000, 3.2000, 1.2000, 0.2000]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.datasets import load_iris, load_digits\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class ClassicDataset(Dataset):\n",
    "    def __init__(self, type='iris'):\n",
    "        sklean_dataset = load_iris() if type=='iris' else load_digits()\n",
    "        self.data = sklean_dataset.data\n",
    "        self.targets = sklean_dataset.target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        y = self.targets[idx]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "# Example usage:\n",
    "iris_dataset = ClassicDataset(type=\"iris\")                              # hyperparameters allowed!\n",
    "train_dataset, val_dataset = random_split(iris_dataset , [0.8, 0.2])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=12, shuffle=True)\n",
    "for (xb, yb) in train_dataloader:\n",
    "    print(xb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Less generally, `torchvision`, `torchaudio` or `torchtext` may have already implemented common custom datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/PvLR9So.png\" width=\"1100\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And they allow transformations! Let's look at:\n",
    "\n",
    "- [Torch Vision Transforms](https://pytorch.org/vision/0.9/transforms.html)\n",
    "\n",
    "- [Torch Audio Transforms](https://pytorch.org/audio/stable/transforms.html)\n",
    "\n",
    "- [Torch Text Transforms](https://pytorch.org/text/stable/transforms.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms        #models has some pretrained models. \n",
    "\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),      #crop a random (within limits) piece and resize to 224x224.\n",
    "        transforms.RandomHorizontalFlip(),      #By default 50% chance to flip the image horizontally.\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5) , (0.25, 0.25, 0.25))\n",
    "    ])\n",
    "\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "        transforms.Resize(256),                 #simply resize the image\n",
    "        transforms.CenterCrop(224),             #center crop of size 244x244\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5) , (0.25, 0.25, 0.25))\n",
    "    ])\n",
    "\n",
    "train_data = datasets.ImageFolder('./data/Hymenoptera/train', train_transforms)\n",
    "val_data = datasets.ImageFolder('./data/Hymenoptera/val', val_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as we said earlier, each of [torchvision](https://pytorch.org/vision/stable/datasets.html), [torchaudio](https://pytorch.org/audio/stable/datasets.html) and [torchtext](https://pytorch.org/text/stable/datasets.html) also tend to come with many popular built-in datasets. Click links to have a look and let's try one out now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89.0M/89.0M [00:51<00:00, 1.80MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "commands_data = torchaudio.datasets.CMUARCTIC(root='.', download=True)      # Speech dataset from CMU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last main component of [torchvision](https://pytorch.org/vision/0.9/models.html), [torchaudio](https://pytorch.org/audio/stable/models.html) and [torchtext](https://pytorch.org/text/stable/models.html) are pretrained models. We can have a look at some of them now but we will try them out later. Note that the `HuggingFace` library, rather `torchtext` dominates the area of NLP pretrained models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ§  Let's Recap\n",
    "\n",
    "- Must wrap dataset in a PyTorch `Dataset` object (from `torch.utils`)\n",
    "\n",
    "- Covered `Dataset` forming whether directly through tensors, custom dataset or helper libraries\n",
    "\n",
    "- Saw that PyTorch helper libraries also offer built-in datasets, transformations and models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of [torch.utils](https://pytorch.org/docs/stable/utils.html) is niche but we may explore more of it later. \n",
    "\n",
    "Before we move on let's discuss how we represent different unstructured data as tensors in deep learning.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<th> Table </th> <th> Images </th> <th> Audio </th> <th> Text </th>\n",
    "<tr>\n",
    "<td> Each observation already a vector </td> \n",
    "<td> \n",
    "\n",
    "Each observation is some $(l,w,3)$ tensor \n",
    "\n",
    "</td> \n",
    "<td> \n",
    "\n",
    "Initially sequence of amplitudes (discrete signal) and typically converted to frequency domain $(n_w,w)$ (e.g., [Mel Spectrogram](https://commons.wikimedia.org/wiki/File:Spektogram_Vokale.png)) \n",
    "\n",
    "</td> \n",
    "<td> \n",
    "\n",
    "Statistical or deep learning approaches to assign word/sentence to a [meaningful vector](https://community.sap.com/t5/technology-blogs-by-members/vector-databases-and-embeddings-revolutionizing-ai-in-rag-in-llm-or-gpt/ba-p/13575985)  \n",
    "\n",
    "</td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may see some examples soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/TEFUEow.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
